%==================================================================================================
% LUKE PHD THESIS BIBTEX FILE
% ---------------------------
% Sorted chronologically
%==================================================================================================

@manual{dsp48,
	author = {Xilinx},
	title = {7 Series DSP48E1 Slice User Guide},
	language = {English},
	version = {Version 1.10},
	organization = {Xilinx},
	pagetotal = {58},
	pubstate = {March 27, 2018}
}

@misc{Charles2013,
	author = {Google},
	title = {Google Test},
	year = {2019},
	publisher = {GitHub},
	journal = {GitHub repository},
	howpublished = {\url{https://github.com/google/googletest}}
}

@article{HeZR015,
	author    = {Kaiming He and
	Xiangyu Zhang and
	Shaoqing Ren and
	Jian Sun},
	title     = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on
	ImageNet Classification},
	journal   = {CoRR},
	volume    = {abs/1502.01852},
	year      = {2015},
	url       = {http://arxiv.org/abs/1502.01852},
	archivePrefix = {arXiv},
	eprint    = {1502.01852},
	timestamp = {Wed, 17 Apr 2019 17:23:45 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/HeZR015},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{paszke2017automatic,
	title={Automatic differentiation in PyTorch},
	author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
	booktitle={NIPS-W},
	year={2017}
}

@article{caffe,
	author    = {Yangqing Jia and
	Evan Shelhamer and
	Jeff Donahue and
	Sergey Karayev and
	Jonathan Long and
	Ross B. Girshick and
	Sergio Guadarrama and
	Trevor Darrell},
	title     = {Caffe: Convolutional Architecture for Fast Feature Embedding},
	journal   = {CoRR},
	volume    = {abs/1408.5093},
	year      = {2014},
	url       = {http://arxiv.org/abs/1408.5093},
	archivePrefix = {arXiv},
	eprint    = {1408.5093},
	timestamp = {Mon, 13 Aug 2018 16:46:41 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/JiaSDKLGGD14},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}



@misc{chollet2015keras,
	title={Keras},
	author={Chollet, Fran\c{c}ois and others},
	year={2015},
	howpublished={\url{https://keras.io}},
}

@misc{tensorflow2015-whitepaper,
	title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
	url={https://www.tensorflow.org/},
	note={Software available from tensorflow.org},
	author={
	Mart\'{\i}n~Abadi and
	Ashish~Agarwal and
	Paul~Barham and
	Eugene~Brevdo and
	Zhifeng~Chen and
	Craig~Citro and
	Greg~S.~Corrado and
	Andy~Davis and
	Jeffrey~Dean and
	Matthieu~Devin and
	Sanjay~Ghemawat and
	Ian~Goodfellow and
	Andrew~Harp and
	Geoffrey~Irving and
	Michael~Isard and
	Yangqing Jia and
	Rafal~Jozefowicz and
	Lukasz~Kaiser and
	Manjunath~Kudlur and
	Josh~Levenberg and
	Dandelion~Man\'{e} and
	Rajat~Monga and
	Sherry~Moore and
	Derek~Murray and
	Chris~Olah and
	Mike~Schuster and
	Jonathon~Shlens and
	Benoit~Steiner and
	Ilya~Sutskever and
	Kunal~Talwar and
	Paul~Tucker and
	Vincent~Vanhoucke and
	Vijay~Vasudevan and
	Fernanda~Vi\'{e}gas and
	Oriol~Vinyals and
	Pete~Warden and
	Martin~Wattenberg and
	Martin~Wicke and
	Yuan~Yu and
	Xiaoqiang~Zheng},
	year={2015},
}
@MASTERSTHESIS {xinbochen2016,
	author = {Xinbo Chen},
	title  = {ENERGY EFFICIENCY ANALYSIS AND OPTIMIZATION OF CONVOLUTIONAL NEURAL NETWORKS FOR IMAGE RECOGNITION},
	school = {Texas State University},
	year   = {2016},
	month  = {may}
}

@inproceedings{Courbariaux2014TrainingDN,
	title={Training deep neural networks with low precision multiplications},
	author={Matthieu Courbariaux and Yoshua Bengio and Jean-Pierre David},
	year={2014}
}

@misc{gmail, title={The mail you want, not the spam you don't}, 
	url={https://gmail.googleblog.com/2015/07/the-mail-you-want-not-spam-you-dont.html},
	note={\url{https://gmail.googleblog.com/2015/07/the-mail-you-want-not-spam-you-dont.html}},
	journal={Official Gmail Blog}, 
	year={2015}, 
	month={Jul}
}

@inproceedings{TABLA,
	author = {Mahajan, Divya and Park, Jongse and Amaro, Emmanuel and Sharma, Hardik and Yazdanbakhsh, Amir and Kyung Kim, Joon and Esmaeilzadeh, Hadi},
	year = {2016},
	month = {03},
	pages = {14-26},
	title = {TABLA: A unified template-based framework for accelerating statistical machine learning},
	doi = {10.1109/HPCA.2016.7446050}
}

@inproceedings{eyeriss,
	author = {Chen, Yu-Hsin and Emer, Joel and Sze, Vivienne},
	title = {Eyeriss: A Spatial Architecture for Energy-efficient Dataflow for Convolutional Neural Networks},
	booktitle = {Proceedings of the 43rd International Symposium on Computer Architecture},
	series = {ISCA '16},
	year = {2016},
	isbn = {978-1-4673-8947-1},
	location = {Seoul, Republic of Korea},
	pages = {367--379},
	numpages = {13},
	url = {https://doi.org/10.1109/ISCA.2016.40},
	doi = {10.1109/ISCA.2016.40},
	acmid = {3001177},
	publisher = {IEEE Press},
	address = {Piscataway, NJ, USA},
} 

@inproceedings{TPU,
	author = {Jouppi, Norman P. and Young, Cliff and Patil, Nishant and Patterson, David and Agrawal, Gaurav and Bajwa, Raminder and Bates, Sarah and Bhatia, Suresh and Boden, Nan and Borchers, Al and Boyle, Rick and Cantin, Pierre-luc and Chao, Clifford and Clark, Chris and Coriell, Jeremy and Daley, Mike and Dau, Matt and Dean, Jeffrey and Gelb, Ben and Ghaemmaghami, Tara Vazir and Gottipati, Rajendra and Gulland, William and Hagmann, Robert and Ho, C. Richard and Hogberg, Doug and Hu, John and Hundt, Robert and Hurt, Dan and Ibarz, Julian and Jaffey, Aaron and Jaworski, Alek and Kaplan, Alexander and Khaitan, Harshit and Killebrew, Daniel and Koch, Andy and Kumar, Naveen and Lacy, Steve and Laudon, James and Law, James and Le, Diemthu and Leary, Chris and Liu, Zhuyuan and Lucke, Kyle and Lundin, Alan and MacKean, Gordon and Maggiore, Adriana and Mahony, Maire and Miller, Kieran and Nagarajan, Rahul and Narayanaswami, Ravi and Ni, Ray and Nix, Kathy and Norrie, Thomas and Omernick, Mark and Penukonda, Narayana and Phelps, Andy and Ross, Jonathan and Ross, Matt and Salek, Amir and Samadiani, Emad and Severn, Chris and Sizikov, Gregory and Snelham, Matthew and Souter, Jed and Steinberg, Dan and Swing, Andy and Tan, Mercedes and Thorson, Gregory and Tian, Bo and Toma, Horia and Tuttle, Erick and Vasudevan, Vijay and Walter, Richard and Wang, Walter and Wilcox, Eric and Yoon, Doe Hyun},
	title = {In-Datacenter Performance Analysis of a Tensor Processing Unit},
	booktitle = {Proceedings of the 44th Annual International Symposium on Computer Architecture},
	series = {ISCA '17},
	year = {2017},
	isbn = {978-1-4503-4892-8},
	location = {Toronto, ON, Canada},
	pages = {1--12},
	numpages = {12},
	url = {http://doi.acm.org/10.1145/3079856.3080246},
	doi = {10.1145/3079856.3080246},
	acmid = {3080246},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {CNN, DNN, GPU, LSTM, MLP, RNN, TPU, TensorFlow, accelerator, deep learning, domain-specific architecture, neural network},
} 

@article{qiao,
	author = {Qiao, Yuran and Shen, Junzhong and Xiao, Tao and Yang, Qianming and Wen, Mei and Zhang, Chunyuan},
	year = {2016},
	month = {05},
	pages = {},
	title = {FPGA-accelerated deep convolutional neural networks for high throughput and energy efficiency: FPGA-ACCELERATED DEEP CONVOLUTIONAL NEURAL NETWORKS},
	journal = {Concurrency and Computation: Practice and Experience},
	doi = {10.1002/cpe.3850}
}

@article{FCNN,
	title={F-CNN: An FPGA-based framework for training Convolutional Neural Networks},
	author={Wenlai Zhao and Haohuan Fu and Wayne Luk and Teng Yu and Shaojun Wang and Bo Feng and Yuchun Ma and Guangwen Yang},
	journal={2016 IEEE 27th International Conference on Application-specific Systems, Architectures and Processors (ASAP)},
	year={2016},
	pages={107-114}
}

@misc{petalinux,
	title  = {Zynq 2016.4 Release},
	author = {XilinxWiki},
	url		= {https://xilinx-wiki.atlassian.net/wiki/spaces/A/pages/18842326/Zynq+2016.4+Release},
	note    = {\url{https://xilinx-wiki.atlassian.net/wiki/spaces/A/pages/18842326/Zynq+2016.4+Release}}
}
@article{translation,
	author    = {Yingce Xia and
	Di He and
	Tao Qin and
	Liwei Wang and
	Nenghai Yu and
	Tie{-}Yan Liu and
	Wei{-}Ying Ma},
	title     = {Dual Learning for Machine Translation},
	journal   = {CoRR},
	volume    = {abs/1611.00179},
	year      = {2016},
	url       = {http://arxiv.org/abs/1611.00179},
	archivePrefix = {arXiv},
	eprint    = {1611.00179},
	timestamp = {Mon, 13 Aug 2018 16:46:54 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/XiaHQWYLM16},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{sm-derivative, title={The Softmax function and its derivative}, note={\url{https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/}}, journal={Eli Benderskys website}}

@misc{q-format,
	title  = {ARM Developer Suite AXD and armsd Debuggers Guide},
	author = {ARM Info center},
	note    = {\url{http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0066d/CHDFAAEI.html}},
	year   = {2001}
}

@article{batch-size,
	author = {M. Radiuk, Pavlo},
	year = {2017},
	month = {12},
	pages = {},
	title = {Impact of Training Set Batch Size on the Performance of Convolutional Neural Networks for Diverse Datasets},
	volume = {20},
	journal = {Information Technology and Management Science},
	doi = {10.1515/itms-2017-0003}
}

@inproceedings{Krizhevsky,
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	title = {ImageNet Classification with Deep Convolutional Neural Networks},
	booktitle = {Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1},
	series = {NIPS'12},
	year = {2012},
	location = {Lake Tahoe, Nevada},
	pages = {1097--1105},
	numpages = {9},
	url = {http://dl.acm.org/citation.cfm?id=2999134.2999257},
	acmid = {2999257},
	publisher = {Curran Associates Inc.},
	address = {USA},
} 


@inproceedings{deepface,
	author = {Taigman, Yaniv and Yang, Ming and Ranzato, Marc'Aurelio and Wolf, Lior},
	year = {2014},
	month = {09},
	pages = {},
	title = {DeepFace: Closing the Gap to Human-Level Performance in Face Verification},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	doi = {10.1109/CVPR.2014.220}
}

@inbook{fine-grained-gpu,
	author = {Jiang, Wenbin and Zhang, Yangsong and Liu, Pai and Ye, Geyan and Jin, Hai},
	year = {2018},
	month = {10},
	pages = {321-330},
	title = {FiLayer: A Novel Fine-Grained Layer-Wise Parallelism Strategy for Deep Neural Networks: 27th International Conference on Artificial Neural Networks, Rhodes, Greece, October 4–7, 2018, Proceedings, Part III},
	isbn = {978-3-030-01423-0},
	doi = {10.1007/978-3-030-01424-7_32}
}

@misc{grad-check-stanford,
	author = {Andrej Karpathy},
	title  = {CS231n Convolutional Neural Networks for Visual Recognition},
	url    = {http://cs231n.github.io/neural-networks-3},
	note   = {\url{http://cs231n.github.io/neural-networks-3}}
}

@article{Lu2019DyingRA,
	title={Dying ReLU and Initialization: Theory and Numerical Examples},
	author={Lu Lu and Yeonjong Shin and Yanhui Su and George Em Karniadakis},
	journal={CoRR},
	year={2019},
	volume={abs/1903.06733}
}
@InProceedings{pmlr-v15-glorot11a,
	title = 	 {Deep Sparse Rectifier Neural Networks},
	author = 	 {Xavier Glorot and Antoine Bordes and Yoshua Bengio},
	booktitle = 	 {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
	pages = 	 {315--323},
	year = 	 {2011},
	editor = 	 {Geoffrey Gordon and David Dunson and Miroslav Dudík},
	volume = 	 {15},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Fort Lauderdale, FL, USA},
	month = 	 {11--13 Apr},
	publisher = 	 {PMLR},
	pdf = 	 {http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf},
	url = 	 {http://proceedings.mlr.press/v15/glorot11a.html},
	abstract = 	 {While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neurons are an even better model of biological neurons and yield equal or better performance than hyperbolic tangent networks in spite of the hard non-linearity and non-differentiability at zero, creating sparse representations with true zeros which seem remarkably suitable for naturally sparse data. Even though they can take advantage of semi-supervised setups with extra-unlabeled data, deep rectifier networks can reach their best performance without requiring any unsupervised pre-training on purely supervised tasks with large labeled datasets. Hence, these results can be seen as a new milestone in the attempts at understanding the difficulty in training deep but purely supervised neural networks, and closing the performance gap between neural networks learnt with and without unsupervised pre-training. [pdf]}
}