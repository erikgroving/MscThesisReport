\chapter{Hardware Model Testing and Verification}
Verification is a vital part of hardware design. For this project, all relevant functionality in the FPGA was verified by simulation or by using MMIO in real-time.
\section{Simulation}
During FPGA development, four different testbenches were created to test the functionality of the design. The first three were module level testbenches to test the scheduler, fully-connected layer, and softmax layers. The fourth testbench tests the entire FPGA design, thus verification of the fourth testbench means that all modules are functional. Therefore, this section will discuss verification of the fourth testbench, which is a full test of the network: \texttt{neural\_net\_top\_tb.sv}, found in the directory \textit{FPGA/FPGA.srcs/sim\_1/new} of the GitHub repository as well as in Appendix \todo[inline]{appendix for testbenches}.

\subsection{Project Modifications to Simulate of the Design}
To conduct the full-scale test of the network, an input needed to be provided to the network on which to perform training. This was done by using a BRAM to store a random input generated by the same Python script (\texttt{weight\_coeff.py}) used to generate the weights for the weight BRAMS. When the simulation runs, the input to the network comes from this input BRAM rather than from the PS.

\subsection{Testing Environment}
The Vivado Simulator was used to perform simulation of the hardware. The testbench was run through Vivado's Tcl shell. During the testing process, a simulation would be ran and then diagnostic data in a test file could be  The below commands run from the Vivado Tcl show how to open the project, run the testbench for 50000 ns, and have all output written to a file.
\begin{lstlisting}
Vivado% open_proj FPGA.xpr
Scanning sources...
Finished scanning sources
open_project: Time (s): cpu = 00:00:11 ; elapsed = 00:00:13 . Memory (MB): peak = 322.016 ; gain = 71.828
Vivado% launch_simulation > sim_out
Vivado% run 50000 >> sim_out
\end{lstlisting}

\subsection{Simulation Output}
Verification and debugging was simple through the use of informative simulation output files. The project formatted signal data to be easy to read through the use of \texttt{\$display} statements. An example of this is shown in listing \ref{display-list}. This example is from \texttt{neural\_net\_top.sv} and prints the current cycle number and FC2 output and gradient data; \texttt{sf} and \texttt{sf2} are scaling factors for activations and gradients, respectively. These scaling factors allow the fixed-point Q format values to be displayed as their floating point equivalent. These types of display statements are ubiquitous in the modules of the project. Once verified, most of these display statements were commented out to prevent clutter of the simulation output file.
\begin{lstlisting}[
caption={Example debug code for simulating the functionality of the hardware model}, label={display-list}, language=SystemVerilog, upquote=true]
`ifdef DEBUG
integer clk_cycle;
integer it;

always_ff @(posedge clk) begin
  if (reset) begin
    clk_cycle   <= 0;
  end
  else begin
    clk_cycle   <=  clk_cycle + 1'b1;
  end
  $display("\n\n------ CYCLE %04d ------", clk_cycle);
  	
  $display("---FC2 GRADIENTS---");    
  $display("img_label: %d", img_label);    
  for (it = 0; it < `FC2_NEURONS; it = it + 1) begin
    $display("%02d:\t%f", it, 
      $itor($signed(fc2_gradients[it])) * sf2);
  end
  
  $display("--- FC2 OUT ---");        
  $display("fc2_buf_valid: %01b" , fc2_buf_valid);
  for (it= 0; it < `FC2_NEURONS; it=it+1) begin
    $display("%02d: %f", it, 
      $itor($signed(fc2_act_o_buf[it])) * sf); 
  end
end 
`endif    
\end{lstlisting}

With this output redirected to a text file, signal data per cycle can be easily found. Furthermore, jumping to a previous or next cycle is quick. For example, in Vim, this can be done with by pressing `N' or `n', respectively. This method of debugging with Vim is shown in Figure \ref{vim-out}, displaying the output generated from the code in Listing \ref{display-list}.
\begin{figure}
	\centering 
	\includegraphics[width=\textwidth]{figures/vim_output}
	\caption{Jumping from cycle to cycle to view debugging data using Vim}\label{vim-out}
\end{figure}

\subsection{Correctness of Simulated Outputs}
A Python script was written to aid in verification of the hardware simulation. This script, \texttt{fpga\_forward\_backward\_pass\_test.py}, is located in Appendix \todo[inline]{appendix} as well as in the \textit{misc} folder of the project on GitHub.

This script parses the Xilinx coefficient files for the input to the network, as well as for all the neurons in all the layers and converts them to floating point numbers. The script then performs the forward pass using the parsed weights and prints the outputs. The script then computes the backward pass and also prints out all neuron and weight gradients. The hardware model can then be verified by checking that the outputs at each stage of computation align with the Python script. Note that values are not compared for equality, but for relative correctness, since the Python script uses floating point and the hardware model uses 18-bit fixed point.

Furthermore, to ensure that the script's computed outputs and gradients are correct, the script also implements gradient checking tests for itself. With this assurance,  the script's computed output and gradients were successfully verified as correct and thus could be used as a baseline against which to compare the hardware model. Note that the gradient check testing for the testing script was based on the gradient checks implemented for the software model in Chapter \ref{ch-sw-model}, and example gradient check tests are shown in Listing \ref{py-grad-check}.

\begin{lstlisting}[
caption={Gradient checks for randomly chosen weights in the Python verification script that uses inputs and weights read from the Xilinx coefficient files of the BRAMs in the hardware model. Only three non-zero gradients shown for brevity.}, label={py-grad-check}, language=SystemVerilog, upquote=true]
> python3 fpga_forward_backward_pass_test.py
../FPGA/FPGA.srcs/sources_1/ip/fc0_weights_1.17.coe
../FPGA/FPGA.srcs/sources_1/ip/fc1_weights2_1.17.coe
../FPGA/FPGA.srcs/sources_1/ip/fc2_weights_1.17.coe
Calculated gradient:    -0.003531676695546401
Numerical gradient:     -0.003531676693313557

Calculated gradient:    -0.006374946805618298
Numerical gradient:     -0.0063749433798498956

Calculated gradient:    0.0006677415295515585
Numerical gradient:     0.0006677441533042838
\end{lstlisting}

\paragraph{Forward Pass Verification}
The Python script was used to verify the correctness of the forward pass of the FPGA layer by layer. Forward pass layer outputs for softmax layer from the simulation and script are compared side-by-side in Listing \ref{sm-forward}. Since the softmax output depends on the outputs from FC0, FC1, and FC2, these layer outputs are not shown for the sake of space. From these tests, the simulated forward pass outputs of the hardware model are shown to be correct. The full outputs for every layer may be seen in the \textit{HW\_Verification} folder of the GitHub repository.

\begin{lstlisting}[
caption={Softmax output. All 10 Neuron outputs shown.}, label={sm-forward}, language=SystemVerilog, upquote=true, numbers=none]
SIMULATION                  PYTHON SCRIPT
Neuron		Activation      Neuron		Activation
00			0.102348        0			0.10235213231346099
01			0.096283        1			0.09627338472902423
02			0.089554        2			0.08953177512141873
03			0.100243        3			0.1002532810000227
04			0.086243        4			0.08622264587243636
05			0.113922        5			0.11397991662882098
06			0.093460        6			0.09343919203092571
07			0.100021        7			0.10005157131620508
08			0.111229        8			0.11123918032286678
09			0.106659        9			0.10665692066481845
\end{lstlisting}

\paragraph{Backward Pass Verification}
The backward pass was verified in the same way as the forward pass, though there are many more gradients than outputs. There is 1 gradient for each neuron and weight, totalling over 80,000 gradients. As with the forward pass, all 80,000 gradients may be viewed and confirmed in the \textit{HW\_Verification} folder of the GitHub repository.

Listing \ref{rand-weight-gradients} shows randomly selected weight gradients from each of the fully-connected layers. The weight gradients depend on the neuron gradients, thus the neuron gradients for that layer must be correct for the weight gradients to be correct.

\begin{lstlisting}[
caption={5 randomly selected weight gradients from each of the fully connected layers}, label={rand-weight-gradients}, language=SystemVerilog, upquote=true, numbers=none]
SIMULATION                  PYTHON SCRIPT
Layer FC0
Neuron	Weight	Gradient	Neuron	Weight Gradient
Layer FC1
Neuron	Weight	Gradient	Neuron	Weight Gradient
Layer FC2
Neuron	Weight	Gradient	Neuron	Weight Gradient
\end{lstlisting}

\section{MMIO}
